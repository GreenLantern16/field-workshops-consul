#!/bin/bash

mkdir /root/helm
set-workdir /root/helm
cd /root/helm

#helm chart values
endpoint=$(az resource show --ids "/subscriptions/$(az account show | jq -r .id)/resourceGroups/$(terraform output -state /root/terraform/vnet/terraform.tfstate resource_group_name)/providers/Microsoft.Solutions/applications/hcs/customconsulClusters/hashicorp-consul-cluster" --api-version 2018-09-01-preview | jq -r .properties.consulConfigFile | base64 -d | jq -r .retry_join[0])
cat << EOF > /root/helm/aks.yaml
global:
  image: 'hashicorp/consul-enterprise:1.8.0-ent'
  domain: consul
  datacenter: east-us
  tls:
    enabled: true
    enableAutoEncrypt: true
    caCert:
      secretName: hashicorp-consul-ca-cert
      secretKey: tls.crt
  acls:
    manageSystemACLs: false
  gossipEncryption:
    secretName: hashicorp-consul-gossip-key
    secretKey: key
externalServers:
  enabled: true
  hosts: ["${endpoint}"]
  httpsPort: 443
  useSystemRoots: true
server:
  enabled: false
client:
  enabled: true
  join: ["${endpoint}"]
  extraVolumes:
  - type: 'secret'
    name: 'hashicorp-consul-acl-config'
    load: true
connectInject:
  enabled: true
  default: false
  k8sAllowNamespaces: ["default"]
  aclInjectToken:
    secretName: hashicorp-consul-connect-inject-acl-token
    secretKey: token
  overrideAuthMethodName: hashicorp-consul-k8s-auth-method
EOF

#script to add secrets
cat << "SCRIPT" > /usr/local/bin/setup-k8s-consul-secrets
#!/bin/bash -xe
resource_group=$1
managed_app=$2
cluster=$3
gossip_key=$4
acl_token=$5
injection_token=$6
acl_string=$( jq -n \
                  --arg token "$acl_token" \
                  '{acl: { enabled: true, enable_token_persistence: true, tokens: { agent: $token } } }' )
#base64 the secrets
gossip_key=$(echo -n $gossip_key | base64 -w 0)
acl_token=$(echo -n  $acl_token | base64 -w 0)
injection_token=$(echo -n  $injection_token | base64 -w 0)
acl_config=$(echo -n $acl_string | base64 -w 0)
ca=$(az resource show --ids "/subscriptions/$(az account show | jq -r .id)/resourceGroups/${resource_group}/providers/Microsoft.Solutions/applications/${managed_app}/customconsulClusters/${cluster}" --api-version 2018-09-01-preview | jq -r .properties.consulCaFile)
#create the consul namespace
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Namespace
metadata:
  name: consul
EOF
#acl config
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Secret
metadata:
  name: hashicorp-consul-acl-config
  namespace: consul
type: Opaque
data:
  acl.json: $acl_config
EOF
#tls cert
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Secret
metadata:
  name: hashicorp-consul-ca-cert
  namespace: consul
type: Opaque
data:
  tls.crt: $ca
EOF
#add the gosip key
cat <<EOF | kubectl apply -n consul -f -
apiVersion: v1
kind: Secret
metadata:
  name: hashicorp-consul-gossip-key
type: Opaque
data:
  key: $gossip_key
EOF
cat <<EOF | kubectl apply -n consul -f -
apiVersion: v1
kind: Secret
metadata:
  name: hashicorp-consul-connect-inject-acl-token
type: Opaque
data:
  token: $injection_token
EOF
SCRIPT
chmod +x /usr/local/bin/setup-k8s-consul-secrets

cat << "SCRIPT" > /usr/local/bin/setup-k8s-consul-auth
cat <<EOF | kubectl apply -f -
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: hashicorp-consul-connect-injector-authmethod-svc-account
  namespace: consul
  labels:
    app: consul
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: hashicorp-consul-connect-injector-authmethod-role
  namespace: consul
  labels:
    app: consul
rules:
  - apiGroups: [""]
    resources:
      - serviceaccounts
    verbs:
      - get
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: hashicorp-consul-connect-injector-authmethod-authdelegator-role-binding
  namespace: consul
  labels:
    app: consul
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: "system:auth-delegator"
subjects:
  - kind: ServiceAccount
    name: hashicorp-consul-connect-injector-authmethod-svc-account
    namespace: consul
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: hashicorp-consul-connect-injector-authmethod-serviceaccount-role-binding
  namespace: consul
  labels:
    app: consul
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: "hashicorp-consul-connect-injector-authmethod-role"
subjects:
  - kind: ServiceAccount
    name: hashicorp-consul-connect-injector-authmethod-svc-account
    namespace: consul
EOF
k8s_host=$(terraform output -state /root/terraform/aks/terraform.tfstate aks_cluster_host)
k8s_ca=$(terraform output -state /root/terraform/aks/terraform.tfstate aks_cluster_ca| base64 -d)
k8s_sa=$(kubectl  get sa -n consul hashicorp-consul-connect-injector-authmethod-svc-account -o json | jq -r .secrets[0].name)
k8s_jwt=$(kubectl get secrets -n consul ${k8s_sa} -o json | jq -r .data.token | base64 -d)
consul acl auth-method create -type "kubernetes" \
    -name "hashicorp-consul-k8s-auth-method" \
    -description "k8s auth" \
    -kubernetes-host "${k8s_host}" \
    -kubernetes-ca-cert "${k8s_ca}" \
    -kubernetes-service-account-jwt "${k8s_jwt}"
consul acl binding-rule create -method 'hashicorp-consul-k8s-auth-method' \
    -description 'apps' \
    -bind-type 'service' \
    -bind-name '${serviceaccount.name}' \
    -selector 'serviceaccount.namespace==default'
SCRIPT
chmod +x /usr/local/bin/setup-k8s-consul-auth

#ambassador
#k8s
kubectl apply -f https://www.getambassador.io/yaml/aes-crds.yaml && \
kubectl wait --for condition=established --timeout=90s crd -lproduct=aes && \
kubectl apply -f https://www.getambassador.io/yaml/aes.yaml && \
kubectl -n ambassador wait --for condition=available --timeout=90s deploy -lproduct=aes

#kubectl apply -f  https://www.getambassador.io/yaml/consul/ambassador-consul-connector.yaml
cat <<EOF | kubectl apply -n ambassador -f -
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  name: ambassador-consul-connect
rules:
  - apiGroups: [""]
    resources:
      - secrets
    verbs: ["get", "list", "create", "delete", "patch"]
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: ambassador-consul-connect
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: ambassador-consul-connect
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: ambassador-consul-connect
subjects:
  - kind: ServiceAccount
    name: ambassador-consul-connect
    namespace: ambassador
---
apiVersion: getambassador.io/v2
kind: TLSContext
metadata:
  name: ambassador-consul
spec:
  hosts: []
  secret: ambassador-consul-connect
---
apiVersion: v1
kind: Service
metadata:
  name: ambassador-consul-connector
spec:
  ports:
  - name: ambassador-consul-connector
    port: 80
  selector:
    component: consul-connect
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ambassador-consul-connect-integration
  labels:
    app: ambassador
    component: consul-connect
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ambassador
      component: consul-connect
  strategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: ambassador
        component: consul-connect
      annotations:
        "consul.hashicorp.com/connect-inject": "false"
    spec:
      serviceAccountName: ambassador-consul-connect
      terminationGracePeriodSeconds: 0
      containers:
        - name: consul-connect-integration
          image: quay.io/datawire/ambassador_pro:consul_connect_integration-0.11.0
          imagePullPolicy: Always
          resources:
            limits:
              cpu: 200m
              memory: 200Mi
            requests:
              cpu: 100m
              memory: 50Mi
          env:
            # Consul runs as a DaemonSet on each Node therefore we need to talk to the Host machine.
            # See: https://www.consul.io/docs/platform/k8s/run.html#architecture
            - name: _CONSUL_HOST
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
EOF

#cat <<EOF | kubectl apply -n ambassador -f -
#---
#apiVersion: getambassador.io/v2
#kind: TracingService
#metadata:
#  name: tracing
#spec:
#  service: "jaeger-collector.default.svc.cluster.local:9411"
#  driver: zipkin
#  config: {}
#EOF

#reset the deployment to pick up tracing changes
kubectl rollout restart deployment/ambassador -n ambassador
kubectl wait --for=condition=available --timeout=90s deployment/ambassador -n ambassador

exit 0
