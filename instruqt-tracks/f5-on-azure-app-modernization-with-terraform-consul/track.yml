slug: f5-on-azure-app-modernization-with-terraform-consul
id: mi8hobhrlh96
version: 0.0.1
type: track
title: F5 on Azure - App Modernization with Terraform & Consul
teaser: test-teaser
description: test-description
icon: ""
tags: []
owner: hashicorp
developers:
- lance@hashicorp.com
- kcorbin@hashicorp.com
private: true
published: true
challenges:
- slug: provision-azure-vnets
  id: tmsnsut54k9f
  type: challenge
  title: Provision Azure VNETs
  teaser: Deploy basic network infrastructure using Terraform
  assignment: |-
    In this assignment you will provision the VNets we will use in the following assignments. <br>

    Inspect and deploy the terraform code.

    In the `Shell` tab run the following commands.
    ```
    terraform plan
    terraform apply -auto-approve
    ```

    Their CIDR blocks are listed below:
    ```
    hcs-vnet: 10.1.0.0/16
    shared-svcs-vnet: 10.2.0.0/16
    legacy-vnet: 10.3.0.0/16
    aks-vnet: 10.4.0.0/16
    ```

    You will leverage these VNet in the next few assignments.
  tabs:
  - title: Shell
    type: terminal
    hostname: workstation
  - title: Text Editor
    type: code
    hostname: workstation
    path: /root/terraform/vnet
  difficulty: basic
  timelimit: 3000
- slug: provision-core-services
  id: gipovssxptby
  type: challenge
  title: Provision Core Services
  teaser: Provision Vault, HCS, and AKS using Terraform
  assignment: |-
    You will use Terraform to provision these services in the background while you set up Consul in the next few assignments. <br>

    Start with Vault. Vault is a secrets management solution that we will use to securely store sensitive information such as usernames, passwords, certificates, and tokens.<br>

    In the `Shell` tab run the following commands.
    ```
    cd /root/terraform/vault
    terraform plan
    nohup terraform apply -auto-approve > /root/terraform/vault/terraform.out &
    ```
    Next, provision AKS. This will be the target environment for the microservices based architecture that applications will be refactored to. <br>
    ```
    cd /root/terraform/aks
    terraform plan
    nohup terraform apply -auto-approve > /root/terraform/aks/terraform.out &
    ```
    Last, provision the HashiCorp Consul service. HCS provides Consul as a Managed service on Azure <br>
    ```
    cd /root/terraform/hcs
    terraform plan
    nohup terraform apply -auto-approve > /root/terraform/hcs/terraform.out &
    ```
    These services will take some time to provision, you can continue at anytime and they will continue to run.  You will validate and configure them in later chapters, for now take a few moments to review the Terraform code used to provision each of these services.   There are tabs for each of the three components.
  tabs:
  - title: Shell
    type: terminal
    hostname: workstation
  - title: Vault Terraform Code
    type: code
    hostname: workstation
    path: /root/terraform/vault
  - title: AKS Terraform Code
    type: code
    hostname: workstation
    path: /root/terraform/aks
  - title: HCS Terraform Code
    type: code
    hostname: workstation
    path: /root/terraform/hcs
  difficulty: basic
  timelimit: 3000
- slug: provision-f5
  id: tddd2tm78rzu
  type: challenge
  title: Provision F5
  teaser: Provision an F5 BIG-IP VE using Terraform
  assignment: |-
    Now we will provision the F5 BIG-IP Virtual Edition using Terraform. <br>

    In the `Shell` tab run the following commands.
    ```
    terraform plan
    terraform apply -auto-approve
    ```

    This can take several minutes to complete, while you are waiting
    take the opportunity to review the `Terraform Code` tab to see the IaC definition.

    Once the apply is complete, you can Navigate to the BIG-IP at the IP address in the terraform output.

    **NOTE:** you will need open the URL provided by the output in a separate tab.  If you are using chrome, you
    may be presented with a certificate error, to bypass this you can type "thisisunsafe" into the Chrome window.

    Now you will upload a [provided](https://github.com/hashicorp/field-workshops-consul/blob/f5-tf-consul-app-mod/instruqt-tracks/f5-on-azure-app-modernization-with-terraform-consul/assets/terraform/bigip/templates/asm_policy.xml) ASM policy to the BIG-IP

    Get the credentials from the Terraform output and save them as environment variables.

    ```
    export CREDS=$(terraform output username):$(terraform output admin_password)
    ```

    Upload the provided ASM XML policy via API.

    ```
    curl -sku $CREDS -X POST \
      -H "Content-Type: application/octet-stream" \
      -H "Content-Range: 0-783595/783596" \
      $(terraform output mgmt_url)/mgmt/tm/asm/file-transfer/uploads/asm_policy.xml \
      --data-binary "@templates/asm_policy.xml" | jq .

    ```


    Next, import the uploaded policy.

    ```

    curl -sku $CREDS \
      -H "Content-Type: application/json" \
      -X POST $(terraform output mgmt_url)/mgmt/tm/asm/tasks/import-policy \
      -d '{"filename": "asm_policy.xml", "name": "WAFPolicy"}' | jq .

      ```

      You can review the configured policy by navigating to the `Security -> Application Security -> Security Policies` tab in the F5 management console. <br>
  notes:
  - type: text
    contents: |
      In this exercise we will be provisioning an F5 BIG-IP Virtual Edition.
  tabs:
  - title: Shell
    type: terminal
    hostname: workstation
  - title: Terraform Code
    type: code
    hostname: workstation
    path: /root/terraform/bigip
  difficulty: basic
  timelimit: 3000
- slug: validate-hcs
  id: zkxpyr3mokid
  type: challenge
  title: Validate HCS
  teaser: Verify Vault, HCS, and Consul are operational
  assignment: |2-

    Consul HCS and Vault should now be provisioned and accessible from the corresponding tabs.

    In this exercise we will gather the information required to connect to HCS and securely store this information in Vault.

    In the `Shell` tab run the following commands.
    ```
    vault login -method=userpass username=operations password=Password1
    ```

    Retrieve the bootstrap token and gossip key from HCS and save it to your Vault instance.

    ```
    echo $CONSUL_HTTP_ADDR
    echo $VAULT_ADDR
    bootstrap_token=$(az hcs create-token --resource-group $(terraform output -state /root/terraform/vnet/terraform.tfstate resource_group_name) --name hcs | jq  -r .masterToken.secretId)
    gossip_key=$(az resource show --ids "/subscriptions/$(az account show | jq -r .id)/resourceGroups/$(terraform output -state /root/terraform/vnet/terraform.tfstate resource_group_name)/providers/Microsoft.Solutions/applications/hcs/customconsulClusters/hashicorp-consul-cluster" --api-version 2018-09-01-preview | jq -r .properties.consulConfigFile | base64 -d | jq -r .encrypt)
    vault kv put secret/consul master_token=${bootstrap_token} gossip_key=${gossip_key}
    ```

    Now inspect the credentials.

    ```
    echo $VAULT_ADDR
    vault kv get secret/consul
    ```
    You can use this token to login and explore the Consul UI, use of the master token should be highly restricted, instead let's configure Vault to issue [dynamic secrets](https://www.vaultproject.io/docs/secrets/consul/) for Consul. <br>

    Get a management token for Vault to manage Consul tokens with.
    You can retrieve the privileged token for this operation from Vault.  <br>

    ```
    export CONSUL_HTTP_TOKEN=$(vault kv get -field=master_token secret/consul)
    vault_consul_mgmt_token=$(consul acl token create -policy-name=global-management -description "vault mgmt" | grep SecretID | cut -d ":" -f2 | xargs)

    ```
    Now configure the secrets engine.

    ```
    vault write consul/config/access address=${CONSUL_HTTP_ADDR} token=${vault_consul_mgmt_token}
    vault read consul/config/access
    ```

    Last, create a policy for the operations team, and link it to the Vault role.

    ```
    consul acl policy create -name "ops" -description "admin policy for ops" -rules 'acl = "write" operator = "write" namespace_prefix "" {acl = "write"}'
    vault write consul/roles/ops policies=ops ttl=1h
    ```

    Now you are ready to get a dynamic Consul token from Vault for an operator.
    Validate the token after you fetch it. <br>

    ```
    export CONSUL_HTTP_TOKEN=$(vault read -field token consul/creds/ops)
    consul acl token read -self
    ```

    You can use this token to set up the anonymous policy.

    ```
    echo '
    node_prefix "" {
      policy = "read"
    }
    service_prefix "" {
      policy = "read"
    }
    session_prefix "" {
      policy = "read"
    }
    agent_prefix "" {
      policy = "read"
    }
    query_prefix "" {
      policy = "read"
    }
    operator = "read"' |  consul acl policy create -name anonymous -rules -
    consul acl token update -id anonymous -policy-name anonymous
    ```

    You will use this role in a later assignment to configure access for Consul service consumers.
  tabs:
  - title: Consul
    type: service
    hostname: workstation
    path: /
    port: 8500
  - title: Vault
    type: service
    hostname: workstation
    path: /
    port: 8200
  - title: Text Editor
    type: code
    hostname: workstation
    path: /root
  - title: Shell
    type: terminal
    hostname: workstation
  difficulty: basic
  timelimit: 3000
- slug: deploy-legacy-environments
  id: pp5dlxxhxsxu
  type: challenge
  title: Deploy Legacy environments
  teaser: Migrate an existing VM based application.
  assignment: |2-

    In this assignment we will be deploying the current application into Azure based VM's. <br>

    As part of the cloud migration, the VM's will also be configured to run a consul agent that registers these services with Consul.  This will make it easy to refactor the application, as the application is no longer dependent upon static IP addresses which are hardcoded into configuration and application code. <br>

    Additionally, by registering these services in Consul, it is no longer required to manually manage pool members on the F5 appliances, instead, VIP's can be configured to populate backend pool members by monitoring services in Consul. Whenever the application scales up, down, or moves the BIG-IP will automatically update it's configuration. <br>

    To get started, we've automated the collection of this information, and seeded a `terraform.tfvars` file in the `/root/terraform/legacy` folder.  Review this information, and then kick off the terraform run.

    ```
    terraform plan
    terraform apply --auto-approve
    ```

    The application has now been migrated to the cloud!!! You will explore the environment in the next challange. <br>
  tabs:
  - title: Consul
    type: service
    hostname: workstation
    path: /
    port: 8500
  - title: App
    type: service
    hostname: workstation
    path: /ui
    port: 9090
  - title: Vault
    type: service
    hostname: workstation
    path: /
    port: 8200
  - title: Terraform Code
    type: code
    hostname: workstation
    path: /root/terraform/legacy
  - title: App Access Info
    type: code
    hostname: workstation
    path: /info.txt
  - title: Shell
    type: terminal
    hostname: workstation
  difficulty: basic
  timelimit: 3000
- slug: review-legacy-environment
  id: uduxezyej08m
  type: challenge
  title: Review legacy environment
  teaser: Review the components of the legacy application
  assignment: |-
    Now take a few moments and familiarize yourself with the application environment. <br>

    The VM based application is now configured as part of a VM scale set on Azure.  One of the first challenges that comes up is that instances of the scale set will be provisioned with dynamic IP addresses. <br>

    This makes it difficult to maintain any configuration files which require hard coded IP addresses, luckily Consul can help solve this.

    Consul maintains a real-time catalog of all of the nodes and services in the environment.  You can see this catalog in the Consul UI tab, or by running the following command:

    ```
    consul members
    ```
  tabs:
  - title: Consul
    type: service
    hostname: workstation
    path: /
    port: 8500
  - title: App
    type: service
    hostname: workstation
    path: /ui
    port: 9090
  - title: Vault
    type: service
    hostname: workstation
    path: /
    port: 8200
  - title: Terraform Code
    type: code
    hostname: workstation
    path: /root/terraform/legacy
  - title: App Access Info
    type: code
    hostname: workstation
    path: /info.txt
  - title: Shell
    type: terminal
    hostname: workstation
  difficulty: basic
  timelimit: 3000
- slug: scale-the-application
  id: xlknkvvmbhdz
  type: challenge
  title: Scale the application
  teaser: test
  assignment: test
  difficulty: basic
  timelimit: 3000
- slug: deploy-consul-in-aks
  id: kl3g4mrevbng
  type: challenge
  title: Deploy Consul in AKS
  teaser: test
  assignment: |-
    Now that part of application is containerized you can start move it into AKS.

    The AKS cluster is already provisioned with the following services:
      * [Ambassador Ingress w/Consul](https://www.getambassador.io/docs/latest/howtos/consul/)
      * [F5-BIG Kubernetes Controller](https://clouddocs.f5.com/containers/v2/)


    We can use the BIG-IP as an entry point and continue to use our WAF policy from earlier in the lab.
    The BIG-IP controller can keep track of the Ambassador NodePorts so we can dynamically route traffic into the Connect mesh.
    Ambassador is connect aware, so we can secure it's ingress sidecar with Consul intentions.

    Verify these pods are running.

    ```
    kubectl get pods -n ambassador
    kubectl get pods -n kube-system
    ```

    Get a Consul Ops token from Vault before starting your deployment.

    ```
    export CONSUL_HTTP_TOKEN=$(vault read -field token consul/creds/ops)
    consul acl token read -self
    ```

    Helm is the recommended way to deploy Consul connect into AKS.
    Inspect the deployment.

    ```
    cat /root/helm/aks.yaml
    ```

    You will run a few setup scripts typically performed by Kubernetes operators, inspect the chart, and then deploy it.
    These scripts seed the AKS worker nodes with screts to talk with the HCS service,
    as well as set up the auth method to establish trust between the Kubernetes API, and Consul.

    ```
    setup-k8s-consul-secrets $(terraform output -state /root/terraform/vnet/terraform.tfstate resource_group_name) hcs hashicorp-consul-cluster $(vault kv get -field gossip_key secret/consul) $(vault kv get -field master_token secret/consul) $(vault kv get -field master_token secret/consul)
    setup-k8s-consul-auth
    helm install hashicorp hashicorp/consul -f aks.yaml --namespace consul --wait --debug
    ```

    Check the components.

    ```
    kubectl get pods -n consul
    ```

    Move to the next assignment when they are ready.
  tabs:
  - title: Consul
    type: service
    hostname: workstation
    path: /
    port: 8500
  - title: Vault
    type: service
    hostname: workstation
    path: /
    port: 8200
  - title: Shell
    type: terminal
    hostname: workstation
  - title: Helm
    type: code
    hostname: workstation
    path: /root/helm/aks.yaml
  difficulty: basic
  timelimit: 3000
- slug: deploy-app-in-k8s
  id: 6jjypzuphebv
  type: challenge
  title: Deploy App in k8s
  teaser: test
  assignment: |-
    With AKS connected to HCS you can deploy your application pods.
    Consul will auto inject sidecars for each pod.

    Deploy the Pods and wait until they are ready.

    ```
    kubectl apply -f apps
    kubectl get pods
    ```

    Now you need to expose the Web application the outside world.
    You will first set up an Ambassador mapping, and then expose Ambassador to the outside world with annotations for BIG-IP

    ```
    cat <<EOF | kubectl apply -f -
    ---
    apiVersion: getambassador.io/v2
    kind: Mapping
    metadata:
      name: consul-web-mapping-tls
    spec:
      prefix: /
      service: web-sidecar-proxy
      resolver: consul-east-us
      tls: ambassador-consul
      load_balancer:
        policy: round_robin
    EOF
    ```

    Next we need to make sure the traffic is allowed between our gateway and the backend pods.
    Update the intentions now.

    ```
    consul intention create --allow default/ambassador default/web
    consul intention create --allow default/web default/api
    consul intention create --allow default/api default/cache
    consul intention create --allow default/api default/currency
    ```

    Annotate the Ambassador service.

    ```
    cat <<EOF | kubectl apply -f -
    ---
    apiVersion: v1
    kind: Service
    metadata:
      name: ambassador
      namespace: ambassador
      labels:
        product: aes
        app.kubernetes.io/component: ambassador-service
        cis.f5.com/as3-tenant: Consul_SD
        cis.f5.com/as3-app: Ambassador
        cis.f5.com/as3-pool: gateway_pool
    spec:
      type: NodePort
      ports:
      - name: https
        port: 443
        targetPort: https
      selector:
        service: ambassador
    EOF
    ```

    Deploy the AS3 declaration.

    ```
    cat <<EOF | kubectl apply -f -
    kind: ConfigMap
    apiVersion: v1
    metadata:
      name: f5-ambassador
      namespace: default
      labels:
        f5type: virtual-server
        as3: "true"
    data:
      template: |
        {
            "class": "AS3",
            "declaration": {
                "class": "ADC",
                "schemaVersion": "3.10.0",
                "id": "urn:uuid:33045210-3ab8-4636-9b2a-c98d22ab915d",
                "label": "http",
                "remark": "A1 example",
                "Consul_SD": {
                    "class": "Tenant",
                    "Ambassador": {
                        "class": "Application",
                        "template": "http",
                        "serviceMain": {
                            "class": "Service_HTTP",
                            "virtualPort": 443,
                            "virtualAddresses": [
                                "10.3.0.4"
                            ],
                            "pool": "gateway_pool"
                        },
                        "gateway_pool": {
                            "class": "Pool",
                            "monitors": [
                                "https"
                            ],
                            "members": [
                                {
                                    "servicePort": 443,
                                    "serverAddresses": []
                                }
                            ]
                        }
                    }
                }
            }
        }
    EOF
    ```
  tabs:
  - title: Consul
    type: service
    hostname: workstation
    path: /
    port: 8500
  - title: Vault
    type: service
    hostname: workstation
    path: /
    port: 8200
  - title: Shell
    type: terminal
    hostname: workstation
  difficulty: basic
  timelimit: 3000
- slug: test-terminating-gateway
  id: z9j7j1geznsv
  type: challenge
  title: Test Terminating Gateway
  teaser: test
  assignment: test
  difficulty: basic
  timelimit: 3000
checksum: "1441152906046363188"
show_timer: true
